<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>تجربة نظارة في الواقع المعزز</title>
    
    <!-- مكتبة Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three/examples/js/loaders/GLTFLoader.js"></script>

    <!-- مكتبات تتبع الوجه -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>

    <style>
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #000;
        }
        video {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
            opacity: 0.5;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="output"></canvas>

    <script>
        let scene, camera, renderer, model, video, canvas, ctx;

        async function init() {
            // إنشاء مشهد Three.js
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 2;
            renderer = new THREE.WebGLRenderer({ alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // تحميل نموذج النظارة glasses1.glb من مجلد المشروع
            const loader = new THREE.GLTFLoader();
            loader.load('./glasses1.glb', (gltf) => {
                console.log("✅ تم تحميل النموذج بنجاح!");  // تحقق من نجاح التحميل
                model = gltf.scene;
                model.scale.set(0.3, 0.3, 0.3); // ضبط الحجم بشكل أكبر
                scene.add(model);
            }, undefined, (error) => {
                console.error('❌ خطأ في تحميل النموذج:', error);
            });

            // إعداد الفيديو والكاميرا
            video = document.getElementById('video');
            canvas = document.getElementById('output');
            ctx = canvas.getContext('2d');
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
            });

            // تحميل نموذج تتبع الوجه
            const faceModel = await facemesh.load();
            
            async function detectFace() {
                const predictions = await faceModel.estimateFaces({ input: video });
                if (predictions.length > 0) {
                    const keypoints = predictions[0].scaledMesh;

                    // نقوم بتحديد النقاط على الوجه
                    const leftEye = keypoints[33]; // العين اليسرى
                    const rightEye = keypoints[133]; // العين اليمنى
                    const nose = keypoints[168]; // نقطة منتصف الأنف

                    // ضبط موضع النظارة بشكل صحيح على الأنف بين العينين
                    if (model) {
                        // حساب المسافة بين العينين لتحديد مكان النظارة
                        const eyeDistance = Math.sqrt(Math.pow(leftEye[0] - rightEye[0], 2) + Math.pow(leftEye[1] - rightEye[1], 2));

                        // وضع النظارة على الأنف بين العينين بناءً على المسافة
                        model.position.set(nose[0] / 100 - 1, -nose[1] / 100 + 1, -2);
                        model.rotation.set(0, 0, 0);  // ضبط زاوية النظارة لتكون بشكل مستقيم
                        model.scale.set(eyeDistance / 200, eyeDistance / 200, eyeDistance / 200); // ضبط حجم النظارة بناءً على المسافة بين العينين
                    }
                }
                requestAnimationFrame(detectFace);
            }
            detectFace();

            function animate() {
                requestAnimationFrame(animate);
                renderer.render(scene, camera);
            }
            animate();
        }
        init();
    </script>
</body>
</html>
